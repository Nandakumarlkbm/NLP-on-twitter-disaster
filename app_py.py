# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E70xW58W2O0cfj49pSeSr3gC7RbWFJQe
"""

import streamlit as st
import pandas as pd
import numpy as np
import re
import nltk
import string 
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')
from nltk.corpus import stopwords
import contractions
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from nltk.stem import WordNetLemmatizer

st.title("IDENTIFICATION OF TWEETS RELATED TO DISASTER AND THOSE NOT RELATED TO DISASTER")

st.write("You can enter your tweet below and the model trained on labeled tweet data provided by Kaggle can predict with above 80% accuracy whether the tweet is related to disaster or not")

st.image(image="https://twitter.com/Twitter/photo")

tweet = st.text_input(label="Enter the tweet you want to identify below:",value="", max_chars=None,placeholder="Enter your tweet here")

def contractionfun(text):
  expanded_words=[]
  for word in text.split():
    expanded_words.append(contractions.fix(word))
  return '  '.join(expanded_words)
def url_remover(text):
  url_patterns = re.sub(r'''(?i)\b((?:https?://|www\d{0,3}[.]|[a-z0-9.\-]+[.][a-z]{2,4}/)(?:[^\s()<>]+|\(([^\s()<>]+|(\([^\s()<>]+\)))*\))+(?:\(([^\s()<>]+|(\([^\s()<>]+\)))*\)|[^\s`!()\[\]{};:'".,<>?«»“”‘’]))''', " ", text)
  return url_patterns

wl = WordNetLemmatizer()

